{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1P_KhRBxtfYRdadx6Qfm1vKPbOojBiNb0","authorship_tag":"ABX9TyPyf1+MsoNsBhe09pN2oi1M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":906},"id":"BDUUMIexfhWE","executionInfo":{"status":"ok","timestamp":1723015770289,"user_tz":-300,"elapsed":4787,"user":{"displayName":"Saleem Khan","userId":"18298827548461057951"}},"outputId":"2d2c788a-76fd-4b35-c897-2f5d938e3f66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.3.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n","Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://40ef7efc9824ed378c.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://40ef7efc9824ed378c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":2}],"source":["!pip install openai==0.28\n","# Import necessary libraries\n","import openai\n","import pandas as pd\n","import numpy as np\n","import gradio as gr\n","\n","# Set up API keys and credentials\n","openai.api_key = 'sk-IBbcgJFY0n9ZsRLWn6_uje_HdvQE_bqWU7Sgy5S1iBT3BlbkFJd6IEqbyRnnI5sGH4yuxYkthJ4iRlvKRPjuvpLC3RMA'\n","# Load and process the data\n","def load_data():\n","    # Sample data loading function\n","    # In a real scenario, upload and read your actual CSV file here\n","    data = {\n","        \"Product\": [\"Widget A\", \"Widget B\", \"Widget C\", \"Widget D\", \"Widget E\"],\n","        \"Sales_Q1\": [500, 300, 200, 600, 150],\n","        \"Sales_Q2\": [600, 400, 250, 700, 200],\n","        \"Sales_Q3\": [700, 350, 300, 750, 250],\n","        \"Sales_Q4\": [800, 450, 350, 800, 300]\n","    }\n","    return pd.DataFrame(data)\n","\n","df = load_data()\n","\n","def query_data(query):\n","    \"\"\"\n","    Function to query the sales data based on a text query.\n","    \"\"\"\n","    if 'sales' in query.lower():\n","        product = query.lower().split('sales of ')[-1].strip()\n","        if product in df['Product'].values:\n","            sales = df[df['Product'] == product].drop('Product', axis=1).values.flatten()\n","            return f\"Sales data for {product.capitalize()}: Q1: {sales[0]}, Q2: {sales[1]}, Q3: {sales[2]}, Q4: {sales[3]}\"\n","        else:\n","            return \"Product not found.\"\n","    else:\n","        return \"Query not understood.\"\n","\n","def process_with_chatgpt(transcript):\n","    \"\"\"\n","    Function to send the transcript to ChatGPT and get a response.\n","    \"\"\"\n","    print(f\"Sending to ChatGPT: {transcript}\")\n","    try:\n","        response = openai.Completion.create(\n","            model=\"gpt-3.5-turbo\",\n","            prompt=transcript,\n","            max_tokens=150\n","        )\n","        chatgpt_response = response.choices[0].text.strip()\n","        return f\"ChatGPT Response: {chatgpt_response}\"\n","    except Exception as e:\n","        return f\"Error during ChatGPT processing: {e}\"\n","\n","def chatbot_response(query):\n","    \"\"\"\n","    Function to handle the chatbot response.\n","    \"\"\"\n","    data_response = query_data(query)\n","    chatgpt_response = process_with_chatgpt(data_response)\n","    return chatgpt_response\n","\n","# Set up Gradio interface\n","def gradio_response(query):\n","    return chatbot_response(query)\n","\n","gr.Interface(fn=gradio_response, inputs=\"text\", outputs=\"text\").launch()\n"]}]}